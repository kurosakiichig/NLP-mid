{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNngjdES/S0Q+UlS5pEdW/J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurosakiichig/SW-mid/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXAQ4whLKqwR",
        "outputId": "c89bc72f-6a62-4ded-93d5-6e8266b9ba07"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 13360\n",
            "-rw-r--r-- 1 root root 13674983 Apr 24 14:01 NBADataset.csv\n",
            "drwxr-xr-x 1 root root     4096 Apr 22 13:37 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import joblib\n",
        "import scipy.sparse\n",
        "\n",
        "# 1. 加载与预处理\n",
        "df = pd.read_csv('NBADataset - 12-07-2020 till 19-09-2020.csv')\n",
        "\n",
        "STOP = set(\n",
        "    \"a about above after again against all am an and any are arent as at be \"\n",
        "    \"because been before being below between both but by couldnt did didnt do \"\n",
        "    \"does doesnt doing dont down during each few for from further had hadnt has hasnt \"\n",
        "    \"have havent having he hed hell hes her here heres hers herself him himself his how \"\n",
        "    \"hows i id ill im ive if in into is isnt it its itself lets me more most mustnt \"\n",
        "    \"my myself no nor not of off on once only or other ought our ours ourselves out over \"\n",
        "    \"own same shant she shed shell shes should shouldnt so some such than that thats the \"\n",
        "    \"their theirs them themselves then there theres these they theyd theyll theyre theyve \"\n",
        "    \"this those through to too under until up very was wasnt we wed well were weve were werent \"\n",
        "    \"what whats when whens where wheres which while who whos whom why whys with wont would wouldnt \"\n",
        "    \"you youd youll youre youve your yours yourself yourselves\"\n",
        ")\n",
        "\n",
        "def clean(text):\n",
        "    t = re.sub(r'https?://\\S+|@\\w+|[^a-zA-Z\\s]', '', str(text)).lower()\n",
        "    return ' '.join(w for w in t.split() if w not in STOP)\n",
        "\n",
        "# 清洗\n",
        "df['clean_text'] = df['text'].apply(clean)\n",
        "# 三分类标签\n",
        "df['sentiment'] = df['polarity'].apply(\n",
        "    lambda p: 'positive' if p > 0 else 'negative' if p < 0 else 'neutral'\n",
        ")\n",
        "\n",
        "# 2. 情感分析：TF-IDF + NB\n",
        "X = df['clean_text']\n",
        "y = df['sentiment']\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model_sent = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1,2))),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "model_sent.fit(X_tr, y_tr)\n",
        "print(\"=== 情感分析 (TF-IDF + NB) ===\")\n",
        "print(classification_report(y_te, model_sent.predict(X_te)))\n",
        "print(confusion_matrix(y_te, model_sent.predict(X_te)))\n",
        "joblib.dump(model_sent, 'sentiment_tfidf_nb.pkl')\n",
        "\n",
        "# 3. 文本排序：纯 N-gram 检索\n",
        "vec_ng = CountVectorizer(max_features=10000, ngram_range=(2,3))\n",
        "gram_mat = vec_ng.fit_transform(df['clean_text'])\n",
        "joblib.dump(vec_ng, 'ngram_vectorizer.pkl')\n",
        "scipy.sparse.save_npz('ngram_matrix.npz', gram_mat)\n",
        "\n",
        "def retrieve(query, top_k=5):\n",
        "    q = clean(query)\n",
        "    qv = vec_ng.transform([q])\n",
        "    sims = cosine_similarity(qv, gram_mat).flatten()\n",
        "    idx = np.argsort(sims)[::-1][:top_k]\n",
        "    results = []\n",
        "    for i in idx:\n",
        "        results.append((df.iloc[i]['text'], float(sims[i])))\n",
        "    return results\n",
        "\n",
        "print(\"\\n=== 检索示例 (N-gram + Cosine) ===\")\n",
        "for txt, sc in retrieve(\"lakers vs warriors\", top_k=5):\n",
        "    print(f\"{sc:.3f} | {txt[:80]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrCDDAPPJ0Vg",
        "outputId": "3036ba03-b082-4377-d19b-4936a801b0eb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 情感分析 (TF-IDF + NB) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.62      0.66      2302\n",
            "     neutral       0.91      0.84      0.87      9649\n",
            "    positive       0.79      0.89      0.83      7670\n",
            "\n",
            "    accuracy                           0.83     19621\n",
            "   macro avg       0.80      0.78      0.79     19621\n",
            "weighted avg       0.84      0.83      0.83     19621\n",
            "\n",
            "[[1421  251  630]\n",
            " [ 310 8126 1213]\n",
            " [ 287  576 6807]]\n",
            "\n",
            "=== 检索示例 (N-gram + Cosine) ===\n",
            "1.000 | Lakers vs Thunder lice now! Busby’s West #busbys #busbyswest #lakers #oklahomaci...\n",
            "0.943 | #NBAPlayoffs Calendario  #LosAngelesLakers  J1 8/18 Lakers vs Blazers 8pm J2 8/2...\n",
            "0.894 | @barstoolsports 2007 Phoenix Suns vs. Spurs series.   Lakers vs Kings Lakers vs ...\n",
            "0.707 | Lakers vs Jazz 6pm Busby’s West #lakers #utahjazz #losangeleslakers #busbys #bus...\n",
            "0.707 | Enjoying this game Lakers vs Raptors #lakers #TorontoRaptors...\n"
          ]
        }
      ]
    }
  ]
}