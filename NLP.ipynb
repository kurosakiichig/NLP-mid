{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0yvktfp5OeonAWDorlh7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurosakiichig/SW-mid/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXAQ4whLKqwR",
        "outputId": "c50f413c-5621-4ddb-d71b-da9746cbc1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 35248\n",
            "-rw-r--r-- 1 root root 33597927 Apr 25 03:46 'NBADataset - 12-07-2020 till 19-09-2020.csv'\n",
            "-rw-r--r-- 1 root root  1216623 Apr 25 04:36  ngram_matrix.npz\n",
            "-rw-r--r-- 1 root root   373789 Apr 25 04:36  ngram_vectorizer.pkl\n",
            "drwxr-xr-x 1 root root     4096 Apr 23 13:39  sample_data\n",
            "-rw-r--r-- 1 root root   886297 Apr 25 04:36  sentiment_tfidf_nb.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import joblib\n",
        "import scipy.sparse\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "df = pd.read_csv('/content/NBADataset - 12-07-2020 till 19-09-2020.csv')\n",
        "STOP = set(\n",
        "    \"a about above after again against all am an and any are arent as at be \"\n",
        "    \"because been before being below between both but by couldnt did didnt do \"\n",
        "    \"does doesnt doing dont down during each few for from further had hadnt has hasnt \"\n",
        "    \"have havent having he hed hell hes her here heres hers herself him himself his how \"\n",
        "    \"hows i id ill im ive if in into is isnt it its itself lets me more most mustnt \"\n",
        "    \"my myself no nor not of off on once only or other ought our ours ourselves out over \"\n",
        "    \"own same shant she shed shell shes should shouldnt so some such than that thats the \"\n",
        "    \"their theirs them themselves then there theres these they theyd theyll theyre theyve \"\n",
        "    \"this those through to too under until up very was wasnt we wed well were weve were werent \"\n",
        "    \"what whats when whens where wheres which while who whos whom why whys with wont would wouldnt \"\n",
        "    \"you youd youll youre youve your yours yourself yourselves\"\n",
        ")\n",
        "\n",
        "def clean(text):\n",
        "    t = re.sub(r'https?://\\S+|@\\w+|[^a-zA-Z\\s]', '', str(text)).lower()\n",
        "    return ' '.join(w for w in t.split() if w not in STOP)\n",
        "\n",
        "# Clean text\n",
        "df['clean_text'] = df['text'].apply(clean)\n",
        "\n",
        "# Convert polarity into 3 sentiment classes\n",
        "df['sentiment'] = df['polarity'].apply(\n",
        "    lambda p: 'positive' if p > 0 else 'negative' if p < 0 else 'neutral'\n",
        ")\n",
        "\n",
        "# 2. Sentiment analysis: TF-IDF + Naive Bayes\n",
        "X = df['clean_text']\n",
        "y = df['sentiment']\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model_sent = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1,2))),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "model_sent.fit(X_tr, y_tr)\n",
        "print(\"=== Sentiment Analysis (TF-IDF + Naive Bayes) ===\")\n",
        "print(classification_report(y_te, model_sent.predict(X_te)))\n",
        "print(confusion_matrix(y_te, model_sent.predict(X_te)))\n",
        "joblib.dump(model_sent, 'sentiment_tfidf_nb.pkl')\n",
        "\n",
        "# 3. Text Retrieval: Pure N-gram Matching\n",
        "vec_ng = CountVectorizer(max_features=10000, ngram_range=(2,3))\n",
        "gram_mat = vec_ng.fit_transform(df['clean_text'])\n",
        "joblib.dump(vec_ng, 'ngram_vectorizer.pkl')\n",
        "scipy.sparse.save_npz('ngram_matrix.npz', gram_mat)\n",
        "\n",
        "def retrieve(query, top_k=5):\n",
        "    q = clean(query)\n",
        "    qv = vec_ng.transform([q])\n",
        "    sims = cosine_similarity(qv, gram_mat).flatten()\n",
        "    idx = np.argsort(sims)[::-1][:top_k]\n",
        "    results = []\n",
        "    for i in idx:\n",
        "        results.append((df.iloc[i]['text'], float(sims[i])))\n",
        "    return results\n",
        "\n",
        "print(\"\\n=== Retrieval Example (N-gram + Cosine Similarity) ===\")\n",
        "for txt, sc in retrieve(\"lakers vs warriors\", top_k=5):\n",
        "    print(f\"{sc:.3f} | {txt[:80]}...\")\n",
        "\n",
        "# 4. Input Examples: Sentiment Classification & Retrieval\n",
        "sample_texts = [\n",
        "    \"The Lakers are unstoppable tonight!\",\n",
        "    \"I canâ€™t believe how bad that refereeing was.\",\n",
        "    \"Neutral comment about the game.\",\n",
        "    \"Amazing comeback by the Heat last night!\",\n",
        "    \"The defense was solid, but the offense was lacking.\",\n",
        "]\n",
        "print(\"\\n=== Sentiment Classification Examples ===\")\n",
        "for t in sample_texts:\n",
        "    print(f\"Text: {t} -> Sentiment: {model_sent.predict([clean(t)])[0]}\")\n",
        "\n",
        "sample_queries = [\n",
        "    \"Warriors championship game analysis\",\n",
        "    \"Raptors playoff performance\",\n",
        "    \"Lakers versus Suns highlights\",\n",
        "    \"Heat season preview\",\n",
        "]\n",
        "print(\"\\n=== Retrieval Example Queries ===\")\n",
        "for q in sample_queries:\n",
        "    print(f\"Query: {q}\")\n",
        "    for txt, sc in retrieve(q, top_k=3):\n",
        "        print(f\"  {sc:.3f} | {txt[:60]}...\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa9JYHBdBS9y",
        "outputId": "0ef8e25d-0800-43c7-cbed-efdf0706b19c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sentiment Analysis (TF-IDF + Naive Bayes) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.62      0.66      2302\n",
            "     neutral       0.91      0.84      0.87      9649\n",
            "    positive       0.79      0.89      0.83      7670\n",
            "\n",
            "    accuracy                           0.83     19621\n",
            "   macro avg       0.80      0.78      0.79     19621\n",
            "weighted avg       0.84      0.83      0.83     19621\n",
            "\n",
            "[[1421  251  630]\n",
            " [ 310 8126 1213]\n",
            " [ 287  576 6807]]\n",
            "\n",
            "=== Retrieval Example (N-gram + Cosine Similarity) ===\n",
            "1.000 | Lakers vs Thunder lice now! Busbyâ€™s West #busbys #busbyswest #lakers #oklahomaci...\n",
            "0.943 | #NBAPlayoffs Calendario  #LosAngelesLakers  J1 8/18 Lakers vs Blazers 8pm J2 8/2...\n",
            "0.894 | @barstoolsports 2007 Phoenix Suns vs. Spurs series.   Lakers vs Kings Lakers vs ...\n",
            "0.707 | Lakers vs Jazz 6pm Busbyâ€™s West #lakers #utahjazz #losangeleslakers #busbys #bus...\n",
            "0.707 | Enjoying this game Lakers vs Raptors #lakers #TorontoRaptors...\n",
            "\n",
            "=== Sentiment Classification Examples ===\n",
            "Text: The Lakers are unstoppable tonight! -> Sentiment: negative\n",
            "Text: I canâ€™t believe how bad that refereeing was. -> Sentiment: negative\n",
            "Text: Neutral comment about the game. -> Sentiment: positive\n",
            "Text: Amazing comeback by the Heat last night! -> Sentiment: positive\n",
            "Text: The defense was solid, but the offense was lacking. -> Sentiment: positive\n",
            "\n",
            "=== Retrieval Example Queries ===\n",
            "Query: Warriors championship game analysis\n",
            "  0.000 | @NBA The @DetroitPistons could have had @spidadmitchell but ...\n",
            "  0.000 | Alberts Saturday Slate  Rockets -5 ðŸ”¨ Djokovich win US Open +...\n",
            "  0.000 | #Nba #HoustonRockets #jamesharden #NBAPlayoffs  #OneMission ...\n",
            "\n",
            "Query: Raptors playoff performance\n",
            "  0.447 | GLUE GUYS PODCAST: Jason Kiddâ€™s Possible Return to the Nets ...\n",
            "  0.447 | Murphyâ€™s ready for his first Raptors playoff game! #tangerin...\n",
            "  0.408 | Murphyâ€™s ready for his first Raptors playoff game! #TorontoR...\n",
            "\n",
            "Query: Lakers versus Suns highlights\n",
            "  0.000 | @NBA The @DetroitPistons could have had @spidadmitchell but ...\n",
            "  0.000 | Alberts Saturday Slate  Rockets -5 ðŸ”¨ Djokovich win US Open +...\n",
            "  0.000 | #Nba #HoustonRockets #jamesharden #NBAPlayoffs  #OneMission ...\n",
            "\n",
            "Query: Heat season preview\n",
            "  0.000 | @NBA The @DetroitPistons could have had @spidadmitchell but ...\n",
            "  0.000 | Alberts Saturday Slate  Rockets -5 ðŸ”¨ Djokovich win US Open +...\n",
            "  0.000 | #Nba #HoustonRockets #jamesharden #NBAPlayoffs  #OneMission ...\n",
            "\n"
          ]
        }
      ]
    }
  ]
}